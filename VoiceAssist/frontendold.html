<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Streaming Frontend</title>
</head>
<body>
    <h1>Audio Streaming to WebSocket Server</h1>
    <button id="openSession">Open Session</button>
    <button id="closeSession" disabled>Close Session</button>
    <div id="status">Status: Session not opened</div>
    <script>
        const openSessionBtn = document.getElementById('openSession');
        const closeSessionBtn = document.getElementById('closeSession');
        const statusDiv = document.getElementById('status');

        let audioContext;
        let socket;
        let stream;
        const CHUNK_SIZE = 4096;
        let isRecording = false;
        async function startAudioProcessing() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000
                    }
                });

                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(CHUNK_SIZE / 2, 1, 1);
                processor.onaudioprocess = (e) => {
                    if (socket?.readyState === WebSocket.OPEN && isRecording) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        const samples = new Int16Array(inputData.length);

                        for (let i = 0; i < inputData.length; i++) {
                            samples[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                        }
                        const chunk = new Int16Array(CHUNK_SIZE / 2);
                        chunk.set(samples);

                        console.log(Sending chunk of ${chunk.buffer.byteLength} bytes);
                        socket.send(chunk.buffer);
                    }
                };
                source.connect(processor);
                processor.connect(audioContext.destination);

                return true;
            } catch (err) {
                console.error('Audio setup error:', err);
                return false;
            }
        }
        function openWebSocket() {
            socket = new WebSocket('ws://127.0.0.1:8000/listen/');
            socket.binaryType = 'arraybuffer';

            socket.onopen = async () => {
                console.log("WebSocket opened");
                if (await startAudioProcessing()) {
                    isRecording = true;
                    statusDiv.textContent = 'Status: Recording...';
                    openSessionBtn.disabled = true;
                    closeSessionBtn.disabled = false;
                } else {
                    socket.close();
                }
            };
            socket.onclose = () => {
                isRecording = false;
                statusDiv.textContent = 'Status: Session closed';
                stream?.getTracks().forEach(track => track.stop());
                audioContext?.close();
                openSessionBtn.disabled = false;
                closeSessionBtn.disabled = true;
            };
        }
        openSessionBtn.addEventListener('click', openWebSocket);
        closeSessionBtn.addEventListener('click', () => socket?.close());
        window.addEventListener('load', openWebSocket);
    </script>
</body>
</html>