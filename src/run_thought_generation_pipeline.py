"""
Pipeline to generate thoughts and save data to JSON.


Module for handling directory paths and file name roots used in the thought generation pipeline.

This module imports constants from `config.py` to define directory paths for unindexed and indexed
model JSON files, as well as file name roots for output JSON files.

Definitions:
    - **Unindexed Models Directory**: Contains JSON files that store model dumps of Pydantic models 
    without indexes.
    - **Indexed Models Directory**: Contains JSON files that store model dumps of Pydantic models 
    with indexes.
    - **File Name Root**: The base name for output JSON files, such as "array_of_thoughts_output" or 
    "rank_of_thoughts_output".

Imported Constants:
    - **OPENAI_UNINDEXED_MODELS_DIR**: Directory for unindexed model JSON files generated by OpenAI.
    - **OPENAI_INDEXED_MODELS_DIR**: Directory for indexed model JSON files generated by OpenAI.
    - **CLAUDE_UNINDEXED_MODELS_DIR**: Directory for unindexed model JSON files generated by Claude.
    - **CLAUDE_INDEXED_MODELS_DIR**: Directory for indexed model JSON files generated by Claude.
    - **RANK_OF_THOUGHTS_FILE_NAME_ROOT**: Base name for JSON files storing rank of thoughts data.
    - **ARRAY_OF_THOUGHTS_FILE_NAME_ROOT**: Base name for JSON files storing array of thoughts data.

These constants are essential for organizing the output locations of the thought generation data 
pipelines.
"""

from pathlib import Path
import logging
import logging_config

from pipelines.horizontal_thoughts_pipeline import (
    parellel_thoughts_generation_wt_openai_pipeline,
    parellel_thoughts_generation_wt_claude_pipeline,
)
from pipelines.vertical_thoughts_pipeline import (
    vertical_thought_wt_openai_pipeline,
    vertical_thought_wt_claude_pipeline,
)
from utils.generate_file_names import generate_dynamic_file_name
from thought_generation.thought_utils import generate_indexed_model_file

from config import (
    OPENAI_UNINDEXED_MODELS_DIR,
    OPENAI_INDEXED_MODELS_DIR,
    CLAUDE_UNINDEXED_MODELS_DIR,
    CLAUDE_INDEXED_MODELS_DIR,
    RANK_OF_THOUGHTS_FILE_NAME_ROOT,
    ARRAY_OF_THOUGHTS_FILE_NAME_ROOT,
    CLAUDE_SONNET,
    CLAUDE_HAIKU,
    GPT_35_TURBO,
    GPT_4_TURBO,
)


# Setup logger
logger = logging.getLogger(__name__)
logger.info("Logging has been configured.")

# Degugging: check directory paths
dirs = [
    OPENAI_UNINDEXED_MODELS_DIR,
    OPENAI_INDEXED_MODELS_DIR,
    CLAUDE_UNINDEXED_MODELS_DIR,
    CLAUDE_INDEXED_MODELS_DIR,
]
logger.info(f"Imported directories from config.py: {dirs}")

# *Pick ideas - topics
ideas = [
    "embedded software development",
    "embedded software development in automotive",
    "embedded software development in aerospace",
]
# other ideas:
# "RTOS (Real-Time Operating System)"

outer_idea = ideas[1]
logger.info(f"top-level idea/topic: {ideas}")


def create_idea_file_path(
    base_dir: Path,
    file_root: str,
    llm_provider: str,
    index_status: str,
    topic: str,
    file_ext: str = "json",
) -> Path:
    """
    Helper function to create a file path for an idea file.

    Args:
        base_dir (Path): Base directory for the file.
        file_root (str): Root name of the file.
        llm_provider (str): LLM provider (e.g., "openai").
        index_status (str): Index status (e.g., "with_index" or "without_index").
        topic (str): Topic for the idea (e.g., the subject of the file).
        file_ext (str): File extension (default is "json").

    Returns:
        Path: Full file path for the idea.
    """
    return base_dir / generate_dynamic_file_name(
        file_root=file_root,
        llm_provider=llm_provider,
        index_status=index_status,
        topic=topic,
        file_ext=file_ext,
    )


def run_pipeline_opeanai(idea: str = outer_idea):  # OpenAI pipeline
    """
    GPT/OpenAI version:
    Run horizontal thoughts pipeline to generate horizontal sub-topics,
    then run vertical thought pipeline to generate vertical sub topics for each.
    """

    logger.info(
        f"Starting pipeline opeanai: generating array of thoughts with OpenAI. \nIdea: {idea}"
    )

    # Step 0: setup model_id (TODO: later set up temperature too)
    default_model = GPT_4_TURBO
    # openai_model_id = default_model  # Set to default or customize
    openai_model_id = GPT_35_TURBO
    # Step 1: set up file paths

    # Common parameters
    llm = "openai"
    wt_idx = "with_index"
    wo_idx = "without_index"
    topic = idea

    # Directories
    not_indexed_files_dir = OPENAI_UNINDEXED_MODELS_DIR
    indexed_files_dir = OPENAI_INDEXED_MODELS_DIR

    # File roots
    file_roots = {
        "rank_of_thoughts": RANK_OF_THOUGHTS_FILE_NAME_ROOT,
        "array_of_thoughts": ARRAY_OF_THOUGHTS_FILE_NAME_ROOT,
    }

    # File paths
    rank_of_thoughts_file = create_idea_file_path(
        base_dir=not_indexed_files_dir,
        file_root=file_roots["rank_of_thoughts"],
        llm_provider=llm,
        index_status=wo_idx,
        topic=topic,
    )
    logger.info(f"rank_of_thoughts_file: {rank_of_thoughts_file}")

    array_of_thoughts_file = create_idea_file_path(
        base_dir=not_indexed_files_dir,
        file_root=file_roots["array_of_thoughts"],
        llm_provider=llm,
        index_status=wo_idx,
        topic=topic,
    )
    logger.info(f"array_of_thoughts_file: {array_of_thoughts_file}")

    indexed_array_of_thoughts_file = create_idea_file_path(
        base_dir=indexed_files_dir,
        file_root=file_roots["array_of_thoughts"],
        llm_provider=llm,
        index_status=wt_idx,
        topic=topic,
    )
    logger.info(f"indexed_array_of_thoughts_file: {indexed_array_of_thoughts_file}")

    # *Step 2: Run pipelines to create & save original (unindexed) rank and array of thougths files
    parellel_thoughts_generation_wt_openai_pipeline(
        idea=idea,
        num_thoughts=10,
        json_file=rank_of_thoughts_file,
        model_id=openai_model_id,
    )
    vertical_thought_wt_openai_pipeline(
        input_json_file=rank_of_thoughts_file,
        output_json_file=array_of_thoughts_file,
        model_id=openai_model_id,
    )
    logger.info(
        f"Rank of thoughts and array of thoughts files for {idea} created and saved."
    )

    # *Step 3: Run pipeline to load the un-indexed array of thoughts file, add index, and save
    # *the new indexed file in the indexed file folder
    unindexed_model_file, indexed_model_file = Path(array_of_thoughts_file), Path(
        indexed_array_of_thoughts_file
    )

    # Run pipeline
    generate_indexed_model_file(unindexed_model_file, indexed_model_file)

    logger.info(
        f"Index version of array of thoughts files for {idea} created and saved."
    )

    logger.info(
        "Finished running pipeline openai: generating array of thoughts with OpenAI."
    )


def run_pipeline_claude(idea: str = outer_idea):  # Claude pipeline
    """
    Claude/Anthropic version:
    Run horizontal thoughts pipeline to generate horizontal sub-topics,
    then run vertical thought pipeline to generate vertical sub topics for each.
    """

    logger.info(
        f"Starting pipeline claude: generating array of thoughts with Claude. \nIdea: {idea}"
    )
    # Step 0: setup model_id (TODO: later set up temperature too)
    default_model = CLAUDE_SONNET
    # claude_model_id = default_model  # Set to default or customize
    claude_model_id = CLAUDE_HAIKU

    # Step 1: set up file paths

    # Common parameters
    llm = "claude"
    wt_idx = "with_index"
    wo_idx = "without_index"
    topic = idea

    # Directories
    not_indexed_idea_dir = CLAUDE_UNINDEXED_MODELS_DIR
    indexed_idea_dir = CLAUDE_INDEXED_MODELS_DIR

    # File roots
    file_roots = {
        "rank_of_thoughts": RANK_OF_THOUGHTS_FILE_NAME_ROOT,
        "array_of_thoughts": ARRAY_OF_THOUGHTS_FILE_NAME_ROOT,
    }

    # File paths
    rank_of_thoughts_file = create_idea_file_path(
        base_dir=not_indexed_idea_dir,
        file_root=file_roots["rank_of_thoughts"],
        llm_provider=llm,
        index_status=wo_idx,
        topic=topic,
    )
    logger.info(f"rank_of_thoughts_file: {rank_of_thoughts_file}")

    array_of_thoughts_file = create_idea_file_path(
        base_dir=not_indexed_idea_dir,
        file_root=file_roots["array_of_thoughts"],
        llm_provider=llm,
        index_status=wo_idx,
        topic=topic,
    )
    logger.info(f"array_of_thoughts_file: {array_of_thoughts_file}")

    indexed_array_of_thoughts_file = create_idea_file_path(
        base_dir=indexed_idea_dir,
        file_root=file_roots["array_of_thoughts"],
        llm_provider=llm,
        index_status=wt_idx,
        topic=topic,
    )
    logger.info(f"indexed_array_of_thoughts_file: {indexed_array_of_thoughts_file}")

    # *Step 2: Run pipelines to create & save original (unindexed) rank and array of thougths files
    parellel_thoughts_generation_wt_claude_pipeline(
        idea=idea,
        num_thoughts=10,
        json_file=rank_of_thoughts_file,
        model_id=claude_model_id,
    )
    vertical_thought_wt_claude_pipeline(
        input_json_file=rank_of_thoughts_file,
        output_json_file=array_of_thoughts_file,
        model_id=claude_model_id,
    )

    logger.info(
        f"Rank of thoughts and array of thoughts files for {idea} created and saved."
    )

    # *Step 3: Run pipeline to load the un-indexed array of thoughts file, add index, and save
    # *the new indexed file in the indexed file folder
    unindexed_model_file, indexed_model_file = Path(array_of_thoughts_file), Path(
        indexed_array_of_thoughts_file
    )

    # Run pipeline
    generate_indexed_model_file(unindexed_model_file, indexed_model_file)

    logger.info(
        f"Index version of array of thoughts files for {idea} created and saved."
    )

    logger.info(
        "Finished running pipeline claude: generating array of thoughts with Claude."
    )


def main():
    """
    Main function for testing and generating sub-thoughts using OpenAI and self-attention.
    """
    run_pipeline_opeanai()
    run_pipeline_claude()


if __name__ == "__main__":
    main()
